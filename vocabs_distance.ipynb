{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 abcdefghijklmnopqrstuvwxyz\n",
      "len(vocabs_pool)=1484\n",
      "len(exclusive_pool)=1484\n"
     ]
    }
   ],
   "source": [
    "lang = \"en\"\n",
    "diff = \"easy\"\n",
    "excl = None\n",
    "\n",
    "vocabs_pool: set[str] = set()  # for faster in operation\n",
    "vocabs_pool_list: list[str] = []  # for consistent results\n",
    "exclusive_pool: set[str] = set()\n",
    "alphabets: list[str] = []\n",
    "\n",
    "with open(rf\"vocabs\\{lang}\\{lang}-{diff}.json\") as file:\n",
    "    json_data = json.load(file)\n",
    "    for d in json_data:\n",
    "        vocabs_pool.add(d)\n",
    "        vocabs_pool_list.append(d)\n",
    "        exclusive_pool.add(d)\n",
    "        alphabets = list(set(alphabets).union(set(d)))\n",
    "\n",
    "if excl is not None:\n",
    "    with open(rf\"vocabs\\{lang}\\{lang}-{excl}.json\") as file:\n",
    "        json_data = json.load(file)\n",
    "        for d in json_data:\n",
    "            exclusive_pool.remove(d)\n",
    "\n",
    "vocabs_pool_list.sort()\n",
    "alphabets.sort()\n",
    "num_vocabs = len(vocabs_pool)\n",
    "print(len(alphabets), \"\".join(alphabets))\n",
    "print(f\"{len(vocabs_pool)=}\")\n",
    "print(f\"{len(exclusive_pool)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bbc', 'cbc', 'dbc', 'ebc', 'fbc', 'gbc', 'hbc', 'ibc', 'jbc', 'kbc', 'lbc', 'mbc', 'nbc', 'obc', 'pbc', 'qbc', 'rbc', 'sbc', 'tbc', 'ubc', 'vbc', 'wbc', 'xbc', 'ybc', 'zbc', 'aac', 'acc', 'adc', 'aec', 'afc', 'agc', 'ahc', 'aic', 'ajc', 'akc', 'alc', 'amc', 'anc', 'aoc', 'apc', 'aqc', 'arc', 'asc', 'atc', 'auc', 'avc', 'awc', 'axc', 'ayc', 'azc', 'aba', 'abb', 'abd', 'abe', 'abf', 'abg', 'abh', 'abi', 'abj', 'abk', 'abl', 'abm', 'abn', 'abo', 'abp', 'abq', 'abr', 'abs', 'abt', 'abu', 'abv', 'abw', 'abx', 'aby', 'abz']\n"
     ]
    }
   ],
   "source": [
    "print(common.change_character(\"abc\", alphabets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, ['admin', 'admit'])\n",
      "(3, ['line', 'fine', 'fire', 'firm'])\n",
      "(-1, [])\n",
      "(-1, [])\n"
     ]
    }
   ],
   "source": [
    "print(common.distance(\"admin\", \"admit\", vocabs_pool, alphabets))\n",
    "print(common.distance(\"line\", \"firm\", vocabs_pool, alphabets))\n",
    "print(common.distance(\"センセイ\", \"モンダイ\", vocabs_pool, alphabets))\n",
    "print(common.distance(\"caro\", \"mano\", vocabs_pool, alphabets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking \"book\"| 148/1484\n",
      "checking \"crush\"| 296/1484\n",
      "checking \"fever\"| 444/1484\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vocabs_pool_list):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vocabs_pool_list):\n\u001b[1;32m---> 16\u001b[0m         dist \u001b[38;5;241m=\u001b[39m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocabs_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphabets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_distance\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[0;32m     20\u001b[0m             difference \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mcharacter_difference(v1, v2)\n",
      "File \u001b[1;32mc:\\Users\\cyrus.kfcheung\\_Workspace\\analyze_word\\common.py:98\u001b[0m, in \u001b[0;36mdistance\u001b[1;34m(from_, to, vocabs_pool, alphabets, max_distance)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cur_distance \u001b[38;5;241m==\u001b[39m max_distance:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_vocab \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchange_character\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphabets\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (new_vocab \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vocab_path) \u001b[38;5;129;01mand\u001b[39;00m (new_vocab \u001b[38;5;129;01min\u001b[39;00m vocabs_pool):\n\u001b[0;32m    100\u001b[0m         vocab_path[new_vocab] \u001b[38;5;241m=\u001b[39m cur_vocab\n",
      "File \u001b[1;32mc:\\Users\\cyrus.kfcheung\\_Workspace\\analyze_word\\common.py:-1\u001b[0m, in \u001b[0;36mchange_character\u001b[1;34m(vocab, alphabets)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# easy: {\"min_distance\": 3, \"max_distance\": 4, \"strict\": False}\n",
    "from collections import defaultdict\n",
    "\n",
    "min_distance = 3\n",
    "max_distance = 4\n",
    "strict = False\n",
    "\n",
    "starter = set()\n",
    "involved = set()\n",
    "counts = defaultdict(lambda: [0, 0, 0])  # vocab, pair, exclusive\n",
    "\n",
    "pairs: list[tuple[str, str]] = []\n",
    "\n",
    "for i, v1 in enumerate(vocabs_pool_list):\n",
    "    for j, v2 in enumerate(vocabs_pool_list):\n",
    "        dist = common.distance(\n",
    "            v1, v2, vocabs_pool, alphabets, max_distance=max_distance\n",
    "        )\n",
    "        if strict:\n",
    "            difference = common.character_difference(v1, v2)\n",
    "            flag = dist[0] > difference and dist[0] >= min_distance\n",
    "        else:\n",
    "            flag = dist[0] >= min_distance\n",
    "\n",
    "        if flag:\n",
    "            counts[len(v1)][1] += 1\n",
    "            starter.add(v1)\n",
    "            involved = involved.union(set(dist[1]))\n",
    "            # print(dist)\n",
    "\n",
    "            if any(v in exclusive_pool for v in dist[1]):\n",
    "                counts[len(v1)][2] += 1\n",
    "                pairs.append((v1, v2))\n",
    "\n",
    "    counts[len(v1)][0] += 1\n",
    "    if (i + 1) % (num_vocabs // 10) == 0:\n",
    "        print(f'checking \"{v1}\"| {i+1}/{num_vocabs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     total_pairs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count_pair\n\u001b[0;32m     28\u001b[0m     total_exclusive \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count_exlusive\n\u001b[1;32m---> 30\u001b[0m pair_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtotal_pairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_combinations\u001b[49m\n\u001b[0;32m     31\u001b[0m exclusive_rate \u001b[38;5;241m=\u001b[39m total_exclusive \u001b[38;5;241m/\u001b[39m total_combinations\n\u001b[0;32m     32\u001b[0m to_print \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_vocab\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexclusive_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m ]\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "total_vocab = 0\n",
    "total_combinations = 0\n",
    "total_pairs = 0\n",
    "total_exclusive = 0\n",
    "\n",
    "print_table = []\n",
    "for k, v in counts.items():\n",
    "    count_vocab = v[0]\n",
    "    vocab_combinations = count_vocab * (count_vocab - 1)\n",
    "    count_pair = v[1]\n",
    "    count_exlusive = v[2]\n",
    "\n",
    "    cur_pair_rate = count_pair / vocab_combinations\n",
    "    cur_exclusive_rate = count_exlusive / vocab_combinations\n",
    "    to_print = [\n",
    "        f\"len {k}\",\n",
    "        f\"{count_vocab}\",\n",
    "        f\"{count_pair}/{vocab_combinations}\",\n",
    "        f\"{cur_pair_rate:.2%}\",\n",
    "        f\"{count_exlusive}/{vocab_combinations}\",\n",
    "        f\"{cur_exclusive_rate:.2%}\",\n",
    "    ]\n",
    "    print_table.append(to_print)\n",
    "\n",
    "    total_vocab += count_vocab\n",
    "    total_combinations += vocab_combinations\n",
    "    total_pairs += count_pair\n",
    "    total_exclusive += count_exlusive\n",
    "\n",
    "pair_rate = total_pairs / total_combinations\n",
    "exclusive_rate = total_exclusive / total_combinations\n",
    "to_print = [\n",
    "    f\"total\",\n",
    "    f\"{total_vocab}\",\n",
    "    f\"{total_pairs}/{total_combinations}\",\n",
    "    f\"{pair_rate:.2%}\",\n",
    "    f\"{total_exclusive}/{total_combinations}\",\n",
    "    f\"{exclusive_rate:.2%}\",\n",
    "]\n",
    "print_table.append(to_print)\n",
    "\n",
    "print(f\"----- pair rate & exclusive rate -----\")\n",
    "for items in print_table:\n",
    "    print(\n",
    "        f\"{items[0]:<5}, #{items[1]:5}:\"\n",
    "        f\" {items[2]:>13} = {items[3]:<7} |\"\n",
    "        f\" {items[4]:>13} = {items[5]:<7}\"\n",
    "    )\n",
    "print(\"-\" * 15)\n",
    "\n",
    "starter_rate = len(starter) / num_vocabs\n",
    "print(f\"starter: {len(starter)}/{num_vocabs} = {starter_rate:.2%}\")\n",
    "\n",
    "participation_rate = len(involved) / num_vocabs\n",
    "print(f\"participation: {len(involved)}/{num_vocabs} = {participation_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, ['タイショク', 'タイショウ', 'アイショウ', 'アイジョウ'])\n",
      "(4, ['ショウコウ', 'リョウコウ', 'リョウヨウ', 'キョウヨウ', 'キョウソウ'])\n",
      "(4, ['シュウトク', 'シュウカク', 'シュウカン', 'チュウカン', 'チュウシン'])\n",
      "(4, ['イッショウ', 'ケッショウ', 'ケイショウ', 'タイショウ', 'タイショク'])\n",
      "(3, ['イッショウ', 'インショウ', 'サンショウ', 'サンチョウ'])\n"
     ]
    }
   ],
   "source": [
    "# use _quick to output json\n",
    "\n",
    "random.seed(0)\n",
    "pairs_shuffled = pairs[:3000]\n",
    "random.shuffle(pairs_shuffled)\n",
    "# with open(rf\"vocabs\\{lang}\\{lang}-pairs-{diff}.json\", \"w\") as f:\n",
    "#     json.dump(pairs_shuffled, f)\n",
    "\n",
    "for i in range(5):\n",
    "    pair = pairs_shuffled[i]\n",
    "    dist = common.distance(pair[0], pair[1], vocabs_pool, alphabets)\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_graph():\n",
    "    distance_graph: dict[tuple[str, str], tuple[int, list[str]]] = {}\n",
    "\n",
    "    def calculate_distance(from_: str, to: str):\n",
    "        if (from_, to) in distance_graph:\n",
    "            return\n",
    "\n",
    "        min_distance = -1\n",
    "        min_path = []\n",
    "        for new_vocab in common.change_character(from_, alphabets):\n",
    "            if new_vocab in vocabs_pool:\n",
    "                calculate_distance(new_vocab, to)\n",
    "                distance, path = distance_graph[(new_vocab, to)]\n",
    "                if min_distance == -1 or 0 <= distance < min_distance:\n",
    "                    min_distance = distance + 1\n",
    "                    min_path = [from_] + path\n",
    "        distance_graph[(from_, to)] = (min_distance, min_path)\n",
    "\n",
    "    for v1 in vocabs_pool:\n",
    "        for v2 in vocabs_pool:\n",
    "            calculate_distance(v1, v2)\n",
    "    return distance_graph\n",
    "\n",
    "\n",
    "# distance_graph = create_distance_graph()\n",
    "# print(distance_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
