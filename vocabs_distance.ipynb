{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 ァアィイウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロワヲンヴー\n",
      "len(vocabs_pool)=13155\n",
      "len(exclusive_pool)=13155\n"
     ]
    }
   ],
   "source": [
    "vocabs_pool: set[str] = set()\n",
    "exclusive_pool: set[str] = set()\n",
    "alphabets: set[str] = set()\n",
    "\n",
    "with open(r\"vocabs\\ja\\ja-len4-easy.json\") as file:\n",
    "    json_data = json.load(file)\n",
    "    for d in json_data:\n",
    "        vocabs_pool.add(d)\n",
    "        exclusive_pool.add(d)\n",
    "        alphabets = alphabets.union(set(d))\n",
    "\n",
    "# with open(r\"vocabs\\en\\en-len4-medium.json\") as file:\n",
    "#     json_data = json.load(file)\n",
    "#     for d in json_data:\n",
    "#         exclusive_pool.remove(d)\n",
    "\n",
    "num_vocabs = len(vocabs_pool)\n",
    "print(len(alphabets), \"\".join(sorted(alphabets)))\n",
    "print(f\"{len(vocabs_pool)=}\")\n",
    "print(f\"{len(exclusive_pool)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ヒbc', 'ィbc', 'abュ', 'キbc', 'aザc', 'aカc', 'abー', 'ドbc', 'abザ', 'abム', 'aギc', 'ゲbc', 'ラbc', 'デbc', 'aッc', 'セbc', 'abサ', 'ョbc', 'abギ', 'ニbc', 'モbc', 'aェc', 'アbc', 'abケ', 'エbc', 'abソ', 'フbc', 'ブbc', 'abユ', 'abハ', 'abノ', 'オbc', 'aトc', 'aャc', 'abゲ', 'ンbc', 'ァbc', 'aクc', 'abボ', 'aゲc', 'aルc', 'aィc', 'ズbc', 'aガc', 'マbc', 'aオc', 'aツc', 'aゼc', 'abヤ', 'abウ', 'ヘbc', 'チbc', 'abカ', 'abポ', 'abヒ', 'ェbc', 'aヨc', 'aヅc', 'aニc', 'スbc', 'タbc', 'aゾc', 'ヤbc', 'aュc', 'abリ', 'ゴbc', 'ノbc', 'aブc', 'aホc', 'aウc', 'abモ', 'abダ', 'ゼbc', 'ミbc', 'abヨ', 'abネ', 'ザbc', 'abジ', 'abズ', 'abゾ', 'aモc', 'aヒc', 'ュbc', 'aアc', 'abゼ', 'aノc', 'abイ', 'ケbc', 'abン', 'ボbc', 'aエc', 'aデc', 'トbc', 'aメc', 'aヘc', 'abフ', 'ーbc', 'abツ', 'コbc', 'aコc', 'ハbc', 'aテc', 'ウbc', 'abバ', 'abプ', 'ギbc', 'ルbc', 'abメ', 'aグc', 'aボc', 'aビc', 'ムbc', 'aスc', 'aシc', 'abマ', 'abパ', 'ポbc', 'abエ', 'aゴc', 'aイc', 'aネc', 'abァ', 'バbc', 'aケc', 'aラc', 'aベc', 'abト', 'aソc', 'abド', 'ダbc', 'ガbc', 'aァc', 'abィ', 'ホbc', 'abヅ', 'カbc', 'aタc', 'abタ', 'aズc', 'ロbc', 'aョc', 'aフc', 'シbc', 'aマc', 'abシ', 'abニ', 'aプc', 'abョ', 'aーc', 'aレc', 'ツbc', 'aナc', 'aバc', 'abデ', 'abク', 'abチ', 'abコ', 'abゴ', 'サbc', 'aダc', 'aサc', 'abス', 'aパc', 'aミc', 'グbc', 'abキ', 'aチc', 'abロ', 'ユbc', 'abグ', 'ベbc', 'ナbc', 'abビ', 'abア', 'ャbc', 'abガ', 'ワbc', 'aユc', 'aドc', 'aジc', 'aヤc', 'aロc', 'abセ', 'イbc', 'abッ', 'リbc', 'レbc', 'aハc', 'メbc', 'ビbc', 'abヘ', 'abオ', 'ゾbc', 'abェ', 'abミ', 'abブ', 'クbc', 'aセc', 'abル', 'abテ', 'パbc', 'ッbc', 'ヨbc', 'プbc', 'aムc', 'abホ', 'abナ', 'ヅbc', 'abレ', 'abベ', 'abラ', 'aリc', 'テbc', 'ジbc', 'aポc', 'ソbc', 'aワc', 'ネbc', 'aンc', 'abワ', 'aキc', 'abャ'}\n"
     ]
    }
   ],
   "source": [
    "def change_character(vocab: str) -> set[str]:\n",
    "    new_vocabs = set()\n",
    "    for i, c in enumerate(vocab):\n",
    "        for a in alphabets:\n",
    "            if a != c:\n",
    "                new_vocab = vocab[:i] + a + vocab[i + 1 :]\n",
    "                new_vocabs.add(new_vocab)\n",
    "\n",
    "    return new_vocabs\n",
    "\n",
    "\n",
    "print(change_character(\"abc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_difference(from_: str, to: str) -> int:\n",
    "    count = 0\n",
    "    for c1, c2 in zip(from_, to):\n",
    "        if c1 != c2:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(from_: str, to: str, max_distance=None) -> tuple[int, list[str]]:\n",
    "    vocab_path = {from_: \"\"}\n",
    "    queue = [(from_, 0)]\n",
    "    while queue:\n",
    "        (cur_vocab, cur_distance) = queue.pop(0)\n",
    "        if cur_vocab == to:\n",
    "            path = [cur_vocab]\n",
    "            while path[0] != from_:\n",
    "                path.insert(0, vocab_path[path[0]])\n",
    "            return (cur_distance, path)\n",
    "\n",
    "        if cur_distance == max_distance:\n",
    "            continue\n",
    "\n",
    "        for new_vocab in change_character(cur_vocab):\n",
    "            if (new_vocab not in vocab_path) and (new_vocab in vocabs_pool):\n",
    "                vocab_path[new_vocab] = cur_vocab\n",
    "                queue.append((new_vocab, cur_distance + 1))\n",
    "\n",
    "    return (-1, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, [])\n",
      "(-1, [])\n",
      "(-1, [])\n"
     ]
    }
   ],
   "source": [
    "print(distance(\"admin\", \"admit\"))\n",
    "print(distance(\"dicho\", \"hecha\"))\n",
    "print(distance(\"war\", \"him\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking \"シリョウ\"| 0/607\n",
      "checking \"ゲンパツ\"| 60/607\n",
      "checking \"キコエル\"| 120/607\n",
      "checking \"ヤサシイ\"| 180/607\n",
      "checking \"ソノモノ\"| 240/607\n",
      "checking \"タショウ\"| 300/607\n",
      "checking \"コウカイ\"| 360/607\n",
      "checking \"タタカウ\"| 420/607\n",
      "checking \"タイセイ\"| 480/607\n",
      "checking \"ドウシテ\"| 540/607\n",
      "checking \"イッパン\"| 600/607\n",
      "pair rate: 2254/367842 = 0.61%\n",
      "exclusive pair rate: 2254/367842 = 0.61%\n",
      "starter: 224/607 = 36.90%\n",
      "participation: 244/607 = 40.20%\n"
     ]
    }
   ],
   "source": [
    "max_distance = 4\n",
    "strict = False\n",
    "count = 0\n",
    "count_exclusive = 0\n",
    "starter = set()\n",
    "involved = set()\n",
    "pairs: list[tuple[str, str]] = []\n",
    "\n",
    "for i, v1 in enumerate(vocabs_pool):\n",
    "    for j, v2 in enumerate(vocabs_pool):\n",
    "        dist = distance(v1, v2, max_distance=max_distance)\n",
    "        diff = character_difference(v1, v2)\n",
    "        if (strict and dist[0] > diff) or (not strict and dist[0] > 3):\n",
    "            count += 1\n",
    "            starter.add(v1)\n",
    "            involved = involved.union(set(dist[1]))\n",
    "            # print(dist)\n",
    "\n",
    "            if any(v in exclusive_pool for v in dist[1]):\n",
    "                count_exclusive += 1\n",
    "                pairs.append((v1, v2))\n",
    "\n",
    "    if i % (num_vocabs // 10) == 0:\n",
    "        print(f'checking \"{v1}\"| {i}/{num_vocabs}')\n",
    "\n",
    "total_combinations = num_vocabs * (num_vocabs - 1)\n",
    "\n",
    "pair_rate = count / total_combinations\n",
    "print(f\"pair rate: {count}/{total_combinations} = {pair_rate:.2%}\")\n",
    "\n",
    "exclusive_rate = count_exclusive / total_combinations\n",
    "print(\n",
    "    f\"exclusive pair rate: {count_exclusive}/{total_combinations} = {exclusive_rate:.2%}\"\n",
    ")\n",
    "\n",
    "starter_rate = len(starter) / num_vocabs\n",
    "print(f\"starter: {len(starter)}/{num_vocabs} = {starter_rate:.2%}\")\n",
    "\n",
    "participation_rate = len(involved) / num_vocabs\n",
    "print(f\"participation: {len(involved)}/{num_vocabs} = {participation_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(rf\"vocabs\\ja\\ja-len4-pairs-easy.json\", \"w\") as f:\n",
    "    json.dump(pairs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_graph():\n",
    "    distance_graph: dict[tuple[str, str], tuple[int, list[str]]] = {}\n",
    "\n",
    "    def calculate_distance(from_: str, to: str):\n",
    "        if (from_, to) in distance_graph:\n",
    "            return\n",
    "\n",
    "        min_distance = -1\n",
    "        min_path = []\n",
    "        for new_vocab in change_character(from_):\n",
    "            if new_vocab in vocabs_pool:\n",
    "                calculate_distance(new_vocab, to)\n",
    "                distance, path = distance_graph[(new_vocab, to)]\n",
    "                if min_distance == -1 or 0 <= distance < min_distance:\n",
    "                    min_distance = distance + 1\n",
    "                    min_path = [from_] + path\n",
    "        distance_graph[(from_, to)] = (min_distance, min_path)\n",
    "\n",
    "    for v1 in vocabs_pool:\n",
    "        for v2 in vocabs_pool:\n",
    "            calculate_distance(v1, v2)\n",
    "    return distance_graph\n",
    "\n",
    "\n",
    "# distance_graph = create_distance_graph()\n",
    "# print(distance_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
